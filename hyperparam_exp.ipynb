{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pennylane pandas tensorflow scikit-learn matplotlib seaborn","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torchvision\nprint(torchvision.__version__)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport time\nimport json\nimport logging\nimport itertools\nfrom pathlib import Path\nimport pennylane as qml\nfrom pennylane import numpy as np\nimport autograd.numpy as anp\nimport pandas as pd\nimport tensorflow as tf\nfrom sklearn.decomposition import PCA\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.metrics import f1_score\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Model\nimport matplotlib.pyplot as plt\nfrom pennylane.transforms import add_noise\nfrom pennylane.noise import NoiseModel, op_in\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\ntf.get_logger().setLevel('ERROR')\n\n# ==============================================================================\n# 1. PENGATURAN AWAL: DIREKTORI, LOGGING & KONFIGURASI GLOBAL\n# ==============================================================================\n\nPath(\"results\").mkdir(exist_ok=True)\nPath(\"results/plots\").mkdir(exist_ok=True)\nLOG_FILE = Path(\"results/experiment_log.csv\")\nPLOT_DIR = Path(\"results/plots\")\n\nlogging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\", handlers=[logging.StreamHandler()], force=True)\n\n# ==============================================================================\n# 2. KOMPONEN QCNN (UNITARY, EMBEDDING, SIRKUIT)\n# ==============================================================================\n\ndef U_TTN(params, wires):\n    qml.RY(params[0], wires=wires[0])\n    qml.RY(params[1], wires=wires[1])\n    qml.CNOT(wires=[wires[0], wires[1]])\n\ndef U_5(params, wires):\n    qml.RX(params[0], wires=wires[0]); qml.RX(params[1], wires=wires[1])\n    qml.RZ(params[2], wires=wires[0]); qml.RZ(params[3], wires=wires[1])\n    qml.CRZ(params[4], wires=[wires[1], wires[0]])\n    qml.CRZ(params[5], wires=[wires[0], wires[1]])\n    qml.RX(params[6], wires=wires[0]); qml.RX(params[7], wires=wires[1])\n    qml.RZ(params[8], wires=wires[0]); qml.RZ(params[9], wires=wires[1])\n\ndef U_6(params, wires):\n    qml.RX(params[0], wires=wires[0]); qml.RX(params[1], wires=wires[1])\n    qml.RZ(params[2], wires=wires[0]); qml.RZ(params[3], wires=wires[1])\n    qml.CRX(params[4], wires=[wires[1], wires[0]])\n    qml.CRX(params[5], wires=[wires[0], wires[1]])\n    qml.RX(params[6], wires=wires[0]); qml.RX(params[7], wires=wires[1])\n    qml.RZ(params[8], wires=wires[0]); qml.RZ(params[9], wires=wires[1])\n\ndef U_9(params, wires):\n    qml.Hadamard(wires=wires[0]); qml.Hadamard(wires=wires[1])\n    qml.CZ(wires=[wires[0], wires[1]])\n    qml.RX(params[0], wires=wires[0]); qml.RX(params[1], wires=wires[1])\n\ndef U_13(params, wires):\n    qml.RY(params[0], wires=wires[0]); qml.RY(params[1], wires=wires[1])\n    qml.CRZ(params[2], wires=[wires[1], wires[0]])\n    qml.RY(params[3], wires=wires[0]); qml.RY(params[4], wires=wires[1])\n    qml.CRZ(params[5], wires=[wires[0], wires[1]])\n\ndef U_14(params, wires):\n    qml.RY(params[0], wires=wires[0]); qml.RY(params[1], wires=wires[1])\n    qml.CRX(params[2], wires=[wires[1], wires[0]])\n    qml.RY(params[3], wires=wires[0]); qml.RY(params[4], wires=wires[1])\n    qml.CRX(params[5], wires=[wires[0], wires[1]])\n\ndef U_15(params, wires):\n    qml.RY(params[0], wires=wires[0]); qml.RY(params[1], wires=wires[1])\n    qml.CNOT(wires=[wires[1], wires[0]])\n    qml.RY(params[2], wires=wires[0]); qml.RY(params[3], wires=wires[1])\n    qml.CNOT(wires=[wires[0], wires[1]])\n\ndef U_SO4(params, wires):\n    qml.RY(params[0], wires=wires[0]); qml.RY(params[1], wires=wires[1])\n    qml.CNOT(wires=[wires[0], wires[1]])\n    qml.RY(params[2], wires=wires[0]); qml.RY(params[3], wires=wires[1])\n    qml.CNOT(wires=[wires[0], wires[1]])\n    qml.RY(params[4], wires=wires[0]); qml.RY(params[5], wires=wires[1])\n\ndef U_SU4(params, wires):\n    qml.U3(params[0], params[1], params[2], wires=wires[0])\n    qml.U3(params[3], params[4], params[5], wires=wires[1])\n    qml.CNOT(wires=[wires[0], wires[1]])\n    qml.RY(params[6], wires=wires[0]); qml.RZ(params[7], wires=wires[1])\n    qml.CNOT(wires=[wires[1], wires[0]])\n    qml.RY(params[8], wires=wires[0])\n    qml.CNOT(wires=[wires[0], wires[1]])\n    qml.U3(params[9], params[10], params[11], wires=wires[0])\n    qml.U3(params[12], params[13], params[14], wires=wires[1])\n    \ndef U_HS(params, wires):\n    qml.PauliZ(wires=wires[0]); qml.RY(params[0], wires=wires[1])\n    qml.CZ(wires=[wires[0], wires[1]])\n    qml.CRX(params[0], wires=[wires[1], wires[0]])\n    qml.RY(params[1], wires=wires[1])\n\nUNITARY_GATES = {'U_TTN': {'fn': U_TTN, 'params': 2}, 'U_5': {'fn': U_5, 'params': 10}, 'U_6': {'fn': U_6, 'params': 10}, 'U_9': {'fn': U_9, 'params': 2}, 'U_13': {'fn': U_13, 'params': 6}, 'U_14': {'fn': U_14, 'params': 6}, 'U_15': {'fn': U_15, 'params': 4}, 'U_SO4': {'fn': U_SO4, 'params': 6}, 'U_SU4': {'fn': U_SU4, 'params': 15}, 'U_HS': {'fn': U_HS, 'params': 2}}\n\ndef data_embedding(X, embedding_type='amplitude'):\n    n_qubits = 8\n    if embedding_type == 'amplitude':\n        qml.AmplitudeEmbedding(X, wires=range(n_qubits), normalize=True, pad_with=0.)\n    elif embedding_type == 'qubit':\n        qml.AngleEmbedding(X, wires=range(n_qubits), rotation='Y')\n    elif embedding_type == 'dense':\n        qml.AngleEmbedding(X[:n_qubits], wires=range(n_qubits), rotation='X')\n        qml.AngleEmbedding(X[n_qubits:2*n_qubits], wires=range(n_qubits), rotation='Y')\n    else:\n        raise ValueError(f\"Unknown embedding type: {embedding_type}\")\n\ndef conv_layer(U, params, wires_list):\n    for wires in wires_list:\n        U(params, wires=wires)\n\ndef pooling_layer(V, params, wires_list):\n    for i, wires in enumerate(wires_list):\n        V(params[i*2:(i+1)*2], wires=wires)\n\ndef Pooling_ansatz1(params, wires):\n    qml.CRZ(params[0], wires=[wires[0], wires[1]])\n    qml.PauliX(wires=wires[0])\n    qml.CRX(params[1], wires=[wires[0], wires[1]])\n\ndef qcnn_structure(U_fn, params, U_params, num_classes):\n    num_measurement_qubits = np.ceil(np.log2(num_classes))\n    param_idx = 0\n    conv_layer(U_fn, params[param_idx:param_idx + U_params], [[0, 1], [2, 3], [4, 5], [6, 7]])\n    param_idx += U_params\n    pooling_layer(Pooling_ansatz1, params[param_idx:param_idx + 8], [[1, 0], [3, 2], [5, 4], [7, 6]])\n    param_idx += 8\n    active_wires = [0, 2, 4, 6]\n    if num_measurement_qubits >= 3: return active_wires[:int(num_measurement_qubits)]\n    conv_layer(U_fn, params[param_idx:param_idx + U_params], [[0, 2], [4, 6]])\n    param_idx += U_params\n    pooling_layer(Pooling_ansatz1, params[param_idx:param_idx + 4], [[2, 0], [6, 4]])\n    param_idx += 4\n    active_wires = [0, 4]\n    if num_measurement_qubits == 2: return active_wires\n    conv_layer(U_fn, params[param_idx:param_idx + U_params], [[0, 4]])\n    param_idx += U_params\n    pooling_layer(Pooling_ansatz1, params[param_idx:param_idx + 2], [[4, 0]])\n    return [0]\n\n# ==============================================================================\n# 3. INFRASTRUKTUR: DATA, MODEL, TRAINING, DAN EVALUASI\n# ==============================================================================\n\ndef get_device(n_wires, has_noise):\n    if not has_noise:\n        return qml.device(\"default.qubit\", wires=n_wires)\n    else:\n        return qml.device(\"default.mixed\", wires=n_wires)\n\ndef build_realistic_noise_model(noise_params):\n    \"\"\"Membangun NoiseModel PennyLane dari dictionary parameter noise.\"\"\"\n    # Ekstrak parameter noise dengan nilai default 0 atau None\n    p_single = noise_params.get('depolarizing_single', 0)\n    p_two = noise_params.get('depolarizing_two', 0)\n    t1 = noise_params.get('t1', None)  # dalam nanodetik\n    t2 = noise_params.get('t2', None)  # dalam nanodetik\n\n    if p_single == 0 and p_two == 0 and t1 is None:\n        return None\n\n    noise_map = {}\n\n    # --- Mendefinisikan Fungsi-fungsi Operasi Noise ---\n    def single_qubit_depolarizing(op, **kwargs):\n        # Menerapkan noise depolarisasi setelah gerbang satu-qubit.\n        return [qml.DepolarizingChannel(p_single, wires=w) for w in op.wires] if p_single > 0 else []\n\n    def two_qubit_depolarizing(op, **kwargs):\n        # Menerapkan noise depolarisasi setelah gerbang dua-qubit.\n        return [qml.DepolarizingChannel(p_two, wires=w) for w in op.wires] if p_two > 0 else []\n\n    def thermal_relaxation_single(op, **kwargs):\n        # Mensimulasikan dekoherensi (kehilangan informasi) selama gerbang satu-qubit beroperasi.\n        return [qml.ThermalRelaxationError(0, t1, t2, GATE_TIMES['single_qubit'], wires=w) for w in op.wires] if t1 and t2 else []\n\n    def thermal_relaxation_two(op, **kwargs):\n        # Mensimulasikan dekoherensi selama gerbang dua-qubit beroperasi.\n        return [qml.ThermalRelaxationError(0, t1, t2, GATE_TIMES['two_qubit'], wires=w) for w in op.wires] if t1 and t2 else []\n\n    # --- Memetakan Noise ke Jenis Gerbang ---\n    SINGLE_QUBIT_OPS = op_in([qml.RX, qml.RY, qml.RZ, qml.Hadamard, qml.PauliX, qml.U3])\n    TWO_QUBIT_OPS = op_in([qml.CNOT, qml.CZ, qml.CRX, qml.CRZ])\n    \n    # Menggabungkan noise depolarisasi dan relaksasi termal untuk setiap jenis gerbang\n    noise_map[SINGLE_QUBIT_OPS] = lambda op, **kwargs: single_qubit_depolarizing(op, **kwargs) + thermal_relaxation_single(op, **kwargs)\n    noise_map[TWO_QUBIT_OPS] = lambda op, **kwargs: two_qubit_depolarizing(op, **kwargs) + thermal_relaxation_two(op, **kwargs)\n\n    return NoiseModel(noise_map)\n\n\ndef load_and_preprocess_data(dataset_name, classes):\n    logging.info(f\"Memuat dan memproses dataset: {dataset_name} untuk kelas {classes}\")\n    if dataset_name in [\"mnist\", \"fashion_mnist\"]:\n        (x_train, y_train), (x_test, y_test) = getattr(tf.keras.datasets, dataset_name).load_data()\n        x_train = tf.image.resize(tf.convert_to_tensor(x_train, dtype=tf.float32)[..., tf.newaxis], (32, 32)) / 255.0\n        x_test = tf.image.resize(tf.convert_to_tensor(x_test, dtype=tf.float32)[..., tf.newaxis], (32, 32)) / 255.0\n    elif dataset_name == \"cifar10\":\n        (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n        x_train_float = tf.cast(x_train, tf.float32)\n        x_test_float = tf.cast(x_test, tf.float32)\n        x_train, x_test = tf.image.rgb_to_grayscale(x_train_float) / 255.0, tf.image.rgb_to_grayscale(x_test_float) / 255.0\n    else:\n        raise ValueError(f\"Unsupported dataset: {dataset_name}\")\n    train_filter = np.isin(y_train.flatten(), classes)\n    test_filter = np.isin(y_test.flatten(), classes)\n    X_train, Y_train = x_train.numpy()[train_filter], y_train[train_filter]\n    X_test, Y_test = x_test.numpy()[test_filter], y_test[test_filter]\n    class_map = {old_label: new_label for new_label, old_label in enumerate(classes)}\n    Y_train = np.array([class_map[int(y)] for y in Y_train.flatten()])\n    Y_test = np.array([class_map[int(y)] for y in Y_test.flatten()])\n    return X_train, Y_train, X_test, Y_test\n\ndef apply_dimensionality_reduction(X_train, Y_train, X_test, method, embedding_type):\n    if embedding_type == 'amplitude': target_dim = 256\n    elif embedding_type == 'dense': target_dim = 16\n    else: target_dim = 8\n    logging.info(f\"Menerapkan '{method}' untuk data embedding '{embedding_type}'.\")\n    if method == 'bilinear_resize':\n        if embedding_type != 'amplitude':\n            raise ValueError(f\"Bilinear resizing hanya untuk 'amplitude' embedding, bukan '{embedding_type}'.\")\n    \n        # 2. PROCEED WITH RESIZING\n        try:\n            target_size = int(np.sqrt(target_dim))\n            \n            X_train_tensor = tf.convert_to_tensor(X_train, dtype=tf.float32)\n            X_test_tensor = tf.convert_to_tensor(X_test, dtype=tf.float32)\n            \n            X_train_resized = tf.image.resize(X_train_tensor, (target_size, target_size), method='bilinear')\n            X_test_resized = tf.image.resize(X_test_tensor, (target_size, target_size), method='bilinear')\n            \n            X_train_reduced = tf.reshape(X_train_resized, (X_train_resized.shape[0], -1)).numpy()\n            X_test_reduced = tf.reshape(X_test_resized, (X_test_resized.shape[0], -1)).numpy()\n    \n            return X_train_reduced, X_test_reduced\n        except Exception as e:\n            raise e\n    else:\n        X_train_flat = X_train.reshape(X_train.shape[0], -1)\n        X_test_flat = X_test.reshape(X_test.shape[0], -1)\n        if method == 'pca':\n            reducer = PCA(n_components=target_dim)\n            X_train_reduced = reducer.fit_transform(X_train_flat)\n            X_test_reduced = reducer.transform(X_test_flat)\n        elif method == 'autoencoder':\n            input_dim = X_train_flat.shape[1]\n            encoder_input = layers.Input(shape=(input_dim,), name=\"encoder_input\")\n            encoded_layer = layers.Dense(target_dim, activation='relu')(encoder_input)\n            encoder = Model(encoder_input, encoded_layer, name=\"encoder\")\n            decoder_input = layers.Input(shape=(target_dim,), name=\"decoder_input\")\n            decoded_layer = layers.Dense(input_dim, activation='sigmoid')(decoder_input)\n            decoder = Model(decoder_input, decoded_layer, name=\"decoder\")\n            autoencoder = Model(encoder_input, decoder(encoder.output), name=\"autoencoder\")\n            autoencoder.compile(optimizer='adam', loss='mse')\n            autoencoder.fit(X_train_flat, X_train_flat, epochs=20, batch_size=32, shuffle=True, verbose=0)\n            X_train_reduced, X_test_reduced = encoder.predict(X_train_flat, verbose=0), encoder.predict(X_test_flat, verbose=0)\n        else: raise ValueError(f\"Metode reduksi/persiapan tidak dikenal: {method}\")\n    min_val, max_val = X_train_reduced.min(), X_train_reduced.max()\n    X_train_scaled = (X_train_reduced - min_val) * (np.pi / (max_val - min_val + 1e-9))\n    test_min, test_max = X_test_reduced.min(), X_test_reduced.max()\n    X_test_scaled = (X_test_reduced - test_min) * (np.pi / (test_max - test_min + 1e-9))\n    return X_train_scaled, X_test_scaled\n\n# --- Komponen infrastruktur lainnya (Optimizer, Metrik, Plotting) tidak berubah ---\ndef get_optimizer(name, lr, steps=80):\n    if name.lower() == 'adam': return qml.AdamOptimizer(stepsize=lr)\n    if name.lower() == 'sgd': return qml.GradientDescentOptimizer(stepsize=lr)\n    if name.lower() == 'nesterovmomentum': return qml.NesterovMomentumOptimizer(stepsize=lr)\n    if name.lower() == 'rmsprop': return qml.RMSPropOptimizer(stepsize=lr)\n    if name.lower() == 'spsa': return qml.SPSAOptimizer(maxiter=steps)\n    raise ValueError(f\"Unknown optimizer: {name}\")\n\ndef calculate_metrics(labels, predictions, cost_fn_type):\n    if not len(labels): return 0.0, 0.0\n    pred_labels = [1 if p > 0 else 0 for p in predictions] if cost_fn_type in ('mse', 'mae') else np.argmax(predictions, axis=1)\n    return np.sum(pred_labels == labels) / len(labels), f1_score(labels, pred_labels, average='weighted', zero_division=0)\n\ndef plot_history(history, save_path):\n    plt.style.use(\"seaborn-v0_8-whitegrid\")\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n    ax1.plot(history['cost'], label='Training Loss')\n    ax1.set(title=\"Training Loss vs. Iterasi\", xlabel=\"Iterasi\", ylabel=\"Loss\")\n    ax1.legend()\n    iterations = range(2, len(history['train_acc']) * 2 + 1, 2)\n    ax2.plot(iterations, history['train_acc'], label='Akurasi Training Batch', marker='o', linestyle='--')\n    ax2.set(title=\"Akurasi Training Batch vs. Iterasi\", xlabel=\"Iterasi\", ylabel=\"Akurasi\")\n    ax2.legend()\n    fig.tight_layout()\n    plt.savefig(save_path)\n    plt.close(fig)\n\n# --- Fungsi Inti Eksperimen yang Diperbarui ---\ndef run_single_variation(variation):\n    \"\"\"Menjalankan satu siklus training dan evaluasi penuh untuk satu variasi.\"\"\"\n    start_time = time.time()\n    # Ekstrak dictionary parameter noise dari variasi\n    noise_params = variation.get('noise_params', {})\n    has_noise = bool(noise_params)\n\n    # Langkah 1: Inisialisasi Device Kuantum\n    device = get_device(n_wires=8, has_noise=has_noise)\n    \n    # Langkah 2: Definisi QNode Dasar (menangani error pembacaan/SPAM secara internal)\n    @qml.qnode(device, interface=\"autograd\")\n    def base_quantum_circuit(X, params):\n        unitary_info = UNITARY_GATES[variation['conv_ansatz']]\n        data_embedding(X, embedding_type=variation['embedding'])\n        measurement_wires = qcnn_structure(unitary_info['fn'], params, unitary_info['params'], len(variation['classes']))\n\n        readout_error = noise_params.get('readout_error', 0)\n        if readout_error > 0:\n            # Modelkan error pembacaan simetris dengan BitFlip.\n            # Ini akan membalik state qubit (0->1 atau 1->0) dengan probabilitas `readout_error`.\n            for wire in measurement_wires:\n                qml.BitFlip(readout_error, wires=wire)\n        \n        is_binary = variation['cost_fn'] in ('mse', 'mae')\n        return qml.expval(qml.PauliZ(measurement_wires[0])) if is_binary else qml.probs(wires=measurement_wires)\n\n    # Langkah 3: Bangun sirkuit akhir (bisa ideal atau dengan noise)\n    final_circuit = base_quantum_circuit\n    noise_model = build_realistic_noise_model(noise_params)\n    if noise_model:\n        final_circuit = add_noise(base_quantum_circuit, noise_model)\n        logging.info(\"Model noise realistis telah diterapkan pada sirkuit.\")\n\n    # Langkah 4: Definisi Fungsi Biaya\n    def square_loss(labels, predictions):\n        labels_mapped = anp.array([1 if l == 1 else -1 for l in labels])\n        return anp.mean((labels_mapped - anp.array(predictions)) ** 2)\n        \n    def multiclass_cross_entropy(labels, predictions): loss = 0; [loss := loss - anp.log(anp.clip(p, 1e-9, 1 - 1e-9)[l]) for l, p in zip(labels, predictions)]; return loss / len(labels)\n\n    def cost_fn(params, X, Y):\n        predictions = []\n    \n        for i, x in enumerate(X):\n            pred = final_circuit(x, params)\n            current_shape = np.shape(pred)\n            predictions.append(pred)\n    \n        if (variation['cost_fn'] == 'mse' or variation['cost_fn'] == 'mae'):\n            return square_loss(Y, predictions)\n        else:\n            return multiclass_cross_entropy(Y, predictions)\n\n    # Langkah 6: Muat dan proses data\n    X_train, Y_train, X_test, Y_test = load_and_preprocess_data(variation['dataset'], variation['classes'])\n    X_train, X_test = apply_dimensionality_reduction(X_train, Y_train, X_test, variation['reduction'], variation['embedding'])\n\n    # Langkah 7: Inisialisasi model dan optimizer\n    unitary_info, num_classes = UNITARY_GATES[variation['conv_ansatz']], len(variation['classes'])\n    num_measurement_qubits = np.ceil(np.log2(num_classes))\n    total_params = unitary_info['params'] + 8\n    if num_measurement_qubits < 3: total_params += unitary_info['params'] + 4\n    if num_measurement_qubits < 2: total_params += unitary_info['params'] + 2\n    params = np.random.uniform(0, 2 * np.pi, total_params, requires_grad=True)\n    opt = get_optimizer(variation['optimizer'], variation['learning_rate'], variation['steps'])\n\n    # Langkah 8: Loop Training\n    history = {'cost': [], 'train_acc': []}\n    for it in range(variation['steps']):\n        batch_indices = np.random.randint(0, len(X_train), (variation['batch_size'],))\n        X_batch, Y_batch = X_train[batch_indices], Y_train[batch_indices]\n        params, cost_val = opt.step_and_cost(lambda p: cost_fn(p, X_batch, Y_batch), params)\n        history['cost'].append(cost_val)\n\n        if (it + 1) % 2 == 0:\n            preds_train_batch = [final_circuit(x, params) for x in X_batch]\n            train_acc, _ = calculate_metrics(Y_batch, preds_train_batch, variation['cost_fn'])\n            history['train_acc'].append(train_acc)\n            logging.info(f\"Iter: {it+1:4d} | Cost: {cost_val:.4f} | Akurasi Batch: {train_acc:.4f}\")\n\n    # Langkah 9: Evaluasi Akhir dan Logging\n    final_preds_test = [final_circuit(x, params) for x in X_test]\n    test_acc, test_f1 = calculate_metrics(Y_test, final_preds_test, variation['cost_fn'])\n    logging.info(f\"Akurasi Test: {test_acc:.4f} | F1-score Test: {test_f1:.4f}\")\n\n    variation_id_parts = {k: v for k, v in variation.items() if k != 'noise_params'}\n    variation_id = \"-\".join(map(str, variation_id_parts.values()))\n    plot_path = PLOT_DIR / f\"{variation_id}.png\"\n    plot_history(history, plot_path)\n\n    return {\n        \"variation_id\": variation_id,\n        \"train_time_sec\": round(time.time() - start_time, 2),\n        \"test_acc\": round(test_acc.item(), 4), \"test_f1\": round(test_f1.item(), 4),\n        \"plot_path\": str(plot_path), **variation_id_parts\n    }\n\n# ==============================================================================\n# 4. MANAJEMEN EKSPERIMEN\n# ==============================================================================\ndef generate_variations(grid):\n    \"\"\"Menghasilkan daftar semua variasi eksperimen dari sebuah grid.\"\"\"\n    reps = grid.pop('repetition', 1)\n    noise_configs = grid.pop('noise_configs', {'noiseless': {}})\n\n    keys, values = zip(*grid.items())\n    base_variations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n\n    combined_variations = []\n    for var in base_variations:\n        for name, params in noise_configs.items():\n            new_var = var.copy()\n            new_var['noise_config_name'] = name \n            new_var['noise_params'] = params  \n            combined_variations.append(new_var)\n\n    all_variations = []\n    for var in combined_variations:\n        for i in range(1, reps + 1):\n            rep_var = var.copy()\n            rep_var['repetition'] = i\n            all_variations.append(rep_var)\n\n    def is_valid(v):\n        if v.get('reduction') == 'bilinear_resize' and v.get('embedding') != 'amplitude': return False\n        if v.get('cost_fn') in ('mse', 'mae') and len(v.get('classes', [])) > 2: return False\n        return True\n\n    valid_variations = [v for v in all_variations if is_valid(v)]\n    grid['repetition'] = reps\n    grid['noise_configs'] = noise_configs\n    return valid_variations\n\ndef load_or_initialize_logfile():\n    if LOG_FILE.exists():\n        logging.info(f\"File log ditemukan: {LOG_FILE}\")\n        return pd.read_csv(LOG_FILE)\n    logging.info(\"File log tidak ditemukan. Membuat file baru.\")\n    return pd.DataFrame()\n\ndef get_remaining_variations(all_variations, log_df):\n    if log_df.empty: return all_variations\n    completed_ids = set(log_df['variation_id'].dropna())\n    \n    def get_variation_id(v):\n        id_parts = {k: val for k, val in v.items() if k != 'noise_params'}\n        return \"-\".join(map(str, id_parts.values()))\n        \n    return [v for v in all_variations if get_variation_id(v) not in completed_ids]\n\ndef run_experiment_suite(grid):\n    all_variations = generate_variations(grid)\n    log_df = load_or_initialize_logfile()\n    remaining_variations = get_remaining_variations(all_variations, log_df)\n\n    if not remaining_variations:\n        logging.info(\"Semua variasi eksperimen telah selesai. Selesai.\")\n        return\n\n    logging.info(f\"Total variasi: {len(all_variations)} | Selesai: {len(all_variations) - len(remaining_variations)} | Sisa: {len(remaining_variations)}\")\n\n    for i, variation in enumerate(remaining_variations):\n        log_info = {k:v for k,v in variation.items() if k != 'noise_params'}\n        logging.info(f\"\\n--- Memulai Variasi {i+1}/{len(remaining_variations)} ---\\n{json.dumps(log_info, indent=2)}\")\n        try:\n            result = run_single_variation(variation)\n            log_df = pd.concat([log_df, pd.DataFrame([result])], ignore_index=True)\n            log_df.to_csv(LOG_FILE, index=False)\n            logging.info(f\"--- Variasi {i+1}/{len(remaining_variations)} Selesai. Hasil dicatat di {LOG_FILE} ---\")\n        except Exception as e:\n            logging.error(f\"Variasi gagal: {variation['noise_config_name']}\\nError: {e}\", exc_info=True)\n            id_parts = {k: v for k, v in variation.items() if k != 'noise_params'}\n            failed_result = {\"variation_id\": \"-\".join(map(str, id_parts.values())), \"train_time_sec\": \"FAILED\", **id_parts}\n            log_df = pd.concat([log_df, pd.DataFrame([failed_result])], ignore_index=True)\n            log_df.to_csv(LOG_FILE, index=False)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"EXPERIMENT_GRID = {\n        # \"dataset\": [\"imagenette\", \"mnist\", \"fashion_mnist\", \"cifar10\"],\n        \"dataset\": [\"mnist\"],\n        \"classes\":  [[0, 1]], #mnist\n        # \"classes\":  [[0, 1, 2, 3]], #mnist mul\n        # \"classes\":  [[7, 9]], #fmnist\n        # \"classes\":  [[0, 1, 8, 9]], #fmnist mul\n        # \"classes\":  [[3, 8]], #cifar\n        \"reduction\": [\n                        \"bilinear_resize\",\n                        \"autoencoder\", \n                        \"pca\",\n                     ],\n        \"embedding\": [\"amplitude\", \"dense\", \"qubit\"],\n        # \"embedding\": [\"dense\"],\n        \"conv_ansatz\": [\n            #------------- ANZ 1\n            'U_TTN', 'U_5',\n            #------------- ANZ 2\n            'U_9', 'U_13', \n            # ------------ ANZ 3\n            'U_14', 'U_15', \n            # ------------ ANZ 4\n            'U_SO4', 'U_SU4',\n            # ------------ ANZ 5\n            'U_6', 'U_HS',\n        ],\n        \"optimizer\": [\n            \"Adam\",\n            \n            \"RMSProp\",\n            \"SPSA\", \n            \n            \"SGD\", \n            \"NesterovMomentum\",\n        ],\n        \"cost_fn\": [\"mse\", \"mae\", \"cross_entropy\", ],\n        'learning_rate': [0.01],\n        'batch_size': [32],\n        'steps': [80],\n        'repetition': 1,\n    \n        # --- CONFIGURABLE NOISE MODELS ---\n        'noise_configs': {\n            'noiseless': {},\n            'realistic_nisq': {\n                't1': 150000,                  # T1 relaxation time in nanoseconds (150 µs)\n                't2': 100000,                  # T2 dephasing time in nanoseconds (100 µs)\n                'depolarizing_single': 0.0005, # 0.05% error per single-qubit gate\n                'depolarizing_two': 0.005,     # 0.5% error per two-qubit gate\n                'readout_error': 0.01          # 1% SPAM error probability\n            },\n            # 'high_depolarizing': {\n            #     'depolarizing_single': 0.005,\n            #     'depolarizing_two': 0.05,\n            #     'readout_error': 0.02\n            # }\n        }\n    }\n    \nrun_experiment_suite(EXPERIMENT_GRID)\n\nGATE_TIMES = {\n    'single_qubit': 50,  # Waktu untuk gerbang seperti U3, RY, RX, RZ, H\n    'two_qubit': 300     # Waktu untuk gerbang seperti CNOT, CRX, CRZ, CZ\n}\n\nrun_experiment_suite(EXPERIMENT_GRID)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}